---
title: BERT
date: 2024-02-15 00:00:00 +0800
categories: [model]
tags: [fine-tuning, model, bert]
---

- ğŸ“™Paper: "[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://www.semanticscholar.org/paper/BERT%3A-Pre-training-of-Deep-Bidirectional-for-Devlin-Chang/df2b0e26d0599ce3e70df8a9da02e51594e0e992)"
- ğŸ”‘Public: âœ…
- âš² Area: Model
- ğŸ“… Date: 2019
- ğŸ” Paper Section: methods / fine-tuning
- ğŸ“ References: 63
